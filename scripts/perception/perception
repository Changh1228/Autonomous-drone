#!/usr/bin/env python

#from _future_ import print_function

import sys
import os, copy, math
import rospy
import tf2_ros
import csv
import cv2, imutils
import numpy as np
from sensor_msgs.msg import Image, CompressedImage
from cv_bridge import CvBridge, CvBridgeError
from transform import four_point_transform

from geometry_msgs.msg import PoseStamped, TransformStamped

from localize_traffic_sign import Localizer

# Keras tensorflow
from keras.models import load_model, Sequential


DICT_NAMES = {"airport" :   0,
                "dangerous_curve_left" :    1,
                "dangerous_curve_right" :   2,
                "follow_left" :     3,
                "follow_right" :    4,
                "junction" :    5,
                "no_bicycle" :  6,
                "no_heavy_truck":   7,
                "no_parking" :  8,
                "no_stopping_and_parking" :     9,
                "residential" :     10,
                "road_narrows_from_left" :  11,
                "road_narrows_from_right" :     12,
                "circulation_warning" :     13,
                "stop" :    14
                }

DICT = ["airport","dangerous_curve_left",
                        "dangerous_curve_right",
                        "follow_left",
                        "follow_right",
                        "junction",
                        "no_bicycle",
                        "no_heavy_truck",
                        "no_parking",
                        "no_stopping_and_parking",
                        "residential",
                        "road_narrows_from_left",
                        "road_narrows_from_right",
                        "circulation_warning",
                        "stop"]
class ImageClass:
    def __init__(self, image, timestamp):
        self.image = image
        self.timestamp = timestamp

class ImageWorker:

    def __init__(self, bridge):
        self.bridge = bridge
        self.size_crop = 64
        self.localizer_signs = Localizer() # we could pass the tf_buf used for localizing ourselves
        self.sign_map_list = [] # A list where all the signs will be saved with their respective position
        self.index = 0
        self.singelModel = load_model('/home/chs/dd2419_ws/src/crazyfile/scripts/model/SingleJules.h5') # NN model trained for 21 classes (SIGNS + BAD CLASSES)
        self.singelModel._make_predict_function()


        self.list_loc_signs = []
        self.raw_image_sub = rospy.Subscriber("/cf1/camera/image_raw", Image, self.callback)
        #self.raw_image_sub = rospy.Subscriber("/cf1/camera/image_rect_color", Image, self.callback)
        self.result_img_pub = rospy.Publisher("/myresult", Image, queue_size=2)

        self.counter_detected_signs = 0 # when we reach 500 signs seing I save them in a CSV file and empty the array to start again
        self.clusters_arr = np.empty((0,6)) # where I save the signs with its position. [Label,X,Y,Z,counter,index]
        # where counter is times I have seen the sign in a small area (number elements cluster), index is just to keep track of number clusters
        # and X,Y,Z are average of the signs of each cluster
        self.index_array = 0 # counter of number of clusters

    def get_clusters(self):
        return self.clusters_arr

    def callback(self, data):
        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            print(e)

        image = ImageClass(cv_image, rospy.get_rostime())

        self.detect_shape(image)

        ## -------------------------------- Save every 500 detected signs on a CSV -----------------------------
        if self.counter_detected_signs % 500 == 0:
            #process
            #
            self.clusters_arr = self.clusters_arr[self.clusters_arr[:, 4] > 15] # check has more than 13 elements

            self.counter_detected_signs = 0


    def process_image(self, image, contour, type_form):
        mask_contours = np.zeros((480, 640), np.uint8)

        cv2.fillPoly(mask_contours, pts=[contour],
            color=(255, 255, 255))  # Let just the contour of interest

        if type_form == "triangle":
            mask = cv2.dilate(mask_contours, None, iterations=2)
            mask = cv2.erode(mask, None, iterations=2)
            mask = cv2.GaussianBlur(mask, (5, 5), 0)
            mask_contours = mask

        res = cv2.bitwise_and(image, image, mask=mask_contours)
        lower1 = np.array([0, 0, 0])
        upper1 = np.array([0, 0, 0])
        black_mask = cv2.inRange(res, lower1, upper1)
        res_new = res.copy()
        res_new[black_mask == 255] = (255, 255, 255)
        return res_new

    def detect_shape(self, imgMes):
        # *PREPROCESS IMAGE**
        # copy image for reasons
        img = imgMes.image

        #rospy.loginfo("IMAGE: " + str(img.shape))


        image = img.copy()
        # filter image to improve edge detection
        imageBlurred = cv2.bilateralFilter(image, 5, 80, 80)
        # grayscale and normalise image
        imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # normalise image
        imageNormalised = imageGray.copy()
        cv2.normalize(imageGray, imageNormalised, 50, 230, cv2.NORM_MINMAX)
        # blurr image
        imageBlurred = cv2.GaussianBlur(imageNormalised, (5, 5), 0)

        # *DETECT EDGES AND CONTOURS*
        # canny edge detection
        edgesDetected = cv2.Canny(imageBlurred, 10, 3, 3)
        self.publishImage(edgesDetected, 'canny')
        # find contours
        edges = edgesDetected.copy()
        contours = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]
        # OBS DIFFERENCE: [-2] at end of findContours and no grab_contours


        imageContours = image.copy()
        if len(contours) > 0:
            for cnt in contours:
                # Area restrictor
                area = cv2.contourArea(cnt)
                # print(area)
                if area <= 70 or area > 40000:
                    # print("No contour within limits")
                    continue

                # Convexity restrictor
                # make sure the contour has the right shape by checking the arc^2/area ratio,
                # which value for circle, square or triangle should be less than 30, 22 actually.
                arcLen = cv2.arcLength(cnt, True)
                polyApprox = cv2.approxPolyDP(cnt, 0.1 * arcLen, True)
                if cv2.isContourConvex(polyApprox) == False:
                    continue

                # Find enclosing rectangle
                rect = cv2.minAreaRect(cnt)

                # Warp image
                box = cv2.boxPoints(rect)
                box = np.int0(box)


                imageWarped = self.warpImage(img, box)

                # Check color content of warped image
                colorContent = self.checkColors(imageWarped)  # [Blue, Red, Yellow]
                maxColorContent = np.amax(colorContent)
                # print(maxColorContent)
                if maxColorContent < 0.05:
                    # print("NOT ENOGH COLORS FFS")
                    continue

                # Control shape of contour
                shape = self.determineContourShape(cnt)
                if shape == 'none':
                    continue
                elif shape == 'rectangle':
                    blueContent = colorContent[0]
                    if blueContent < 0.05:
                        continue
                elif shape == 'triangle':
                    image = self.process_image(img, cnt, "triangle")
                    yellowContent = colorContent[2]
                    if yellowContent < 0.05:
                        continue
                elif shape == 'circle':
                    image = self.process_image(img, cnt, "cercle")
                    imageWarped = self.warpImage(image, box)
                    pass



                # Determine position of contour
                x, y, w, h = cv2.boundingRect(cnt)
                center = (x, y)

                # Draw contour on image and classify using NN:
                self.publishImage(imageWarped, 'warp')

                classifiedSign = self.classifySign(imageWarped)
                cv2.drawContours(imageContours, [box], -1, (0, 255, 9), 2)  # draw box
                cv2.putText(imageContours, classifiedSign, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                pose = PoseStamped()
                timeStamp = rospy.Time.now()
                mm = cv2.moments(box)  # cal center

                sign_in_map = self.localizer_signs.find_location((x, y), [(x-0.5*w, y-0.5*h), (x+0.5*w, y-0.5*h),
                    (x-0.5*w, y+0.5*h),(x+0.5*w, y+0.5*h)], imgMes.timestamp)
                #rospy.loginfo("X : "+str(sign_in_map.pose.position.x))
                if sign_in_map is not None and classifiedSign not in ['z_crap','z_crap_airport','z_crap_aruco','z_crap_circ','z_crap_dark','z_crap_park']:
                    posit = sign_in_map.pose.position
                    br = tf2_ros.StaticTransformBroadcaster()
                    tOut = TransformStamped()
                    tOut.header.frame_id = 'map'
                    tOut.child_frame_id = 'cf1/' + classifiedSign
                    tOut.transform.translation = posit
                    tOut.transform.rotation = sign_in_map.pose.orientation
                    br.sendTransform(tOut)
                    self.counter_detected_signs = self.counter_detected_signs + 1

                ## ----------------------Clustering--------------------------------

                    ID_sign = DICT_NAMES[classifiedSign] # Codify label as Integer
                    # Filter to just get the elements of the same sign
                    filtered_by_sign = self.clusters_arr[self.clusters_arr[:, 0] == ID_sign]
                    if filtered_by_sign.size != 0: # Check if that sign is in the cluster array or not, if no add it but if yes
                    # check if the detecetd sign is close to the cluster of the same sign type detected before
                        flag = 0
                        for elements in filtered_by_sign:
                            # if distance less than 2 meters
                            if np.abs(posit.x - elements[1]) + np.abs(posit.y - elements[2]) + np.abs(posit.z - elements[3]) < 2:
                                av_x = (posit.x + elements[1]*elements[4])/float(elements[4]+1) # update average position cluster with new measurement
                                av_y = (posit.y + elements[2]*elements[4])/float(elements[4]+1)
                                av_z = (posit.z + elements[3]*elements[4])/float(elements[4]+1)
                                self.clusters_arr[self.clusters_arr[:,5] == elements[5], :] = [ID_sign, av_x, av_y, av_z, elements[4]+1, elements[5]]
                                flag = 1
                                break
                        if flag == 0: # no sign close to it, so create it
                            self.clusters_arr = np.append(
                                self.clusters_arr,
                                np.array([[ID_sign, posit.x, posit.y, posit.z, 1, self.index_array]]),
                                axis = 0)
                            self.index_array = self.index_array+1
                    else:
                        self.clusters_arr = np.append(
                            self.clusters_arr,
                            np.array([[ID_sign, posit.x, posit.y, posit.z, 1, self.index_array]]),
                            axis = 0)
                        self.index_array = self.index_array+1


        self.publishImage(imageContours, 'imageWithBoxes')


    def classifySign(self, image):
        model = self.singelModel
        classNames = ['airport',
                        'dangerous_curve_left',
                        'dangerous_curve_right',
                        'follow_left',
                        'follow_right',
                        'junction',
                        'no_bicycle',
                        'no_heavy_truck',
                        'no_parking',
                        'no_stopping_and_parking',
                        'residential',
                        'road_narrows_from_left',
                        'road_narrows_from_right',
                        'circulation_warning',
                        'stop',
                        'z_crap',
                        'z_crap_airport',
                        'z_crap_aruco',
                        'z_crap_circ',
                        'z_crap_dark',
                        'z_crap_park']
        imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        imageExpand = np.expand_dims(np.array(imageRGB), 0)
        predict = model.predict(imageExpand)
        signPredictedPos = np.where(predict == np.amax(predict))[1][0]
        signPredicted = classNames[signPredictedPos]
        return signPredicted


    def determineContourShape(self, cnt):
        area = cv2.contourArea(cnt)
        arcLen = cv2.arcLength(cnt, True)
        # Determine min ecnlosing triangle
        val, triangle = cv2.minEnclosingTriangle(cnt)
        triangleArea = cv2.contourArea(triangle)
        # Determine min enclosing rectangle
        rect = cv2.minAreaRect(cnt)
        box = cv2.boxPoints(rect)
        rectangle = np.int0(box)
        rectangleArea = cv2.contourArea(rectangle)
        # Determine min enclosing circle
        (x, y), radius = cv2.minEnclosingCircle(cnt)
        radius = int(radius)
        circleArea = radius * radius * math.pi

        triangleRatio = area / triangleArea
        rectangleRatio = area / rectangleArea
        circleRatio = area / circleArea
        errors = [np.sqrt(np.power(triangleRatio - 1, 2)), np.sqrt(np.power(rectangleRatio - 1, 2)),
                  np.sqrt(np.power(circleRatio - 1, 2))]

        minError = np.amin(errors)
        minErrorPos = np.where(errors == minError)[0][0]
        signShapes = ['triangle', 'rectangle', 'circle']
        if minError > 0.2:
            shape = 'none'
        else:
            shape = signShapes[minErrorPos]

        return shape

    def checkColors(self, image):
        #print("Checking colors")
        width, height = image.shape[:2]
        area = width * height
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # Define color ranges
        lower_blue = np.array([100, 102, 40])  # All: 20,0,0 Black/white: 0,0,250, Blue: 90,80,50
        upper_blue = np.array([115, 205, 165])  # All: 300,300,300 Black/white: 255,5,255, Blue: 110,255,255
        lower_red1 = np.array([129, 65, 90])  # red color part 1
        upper_red1 = np.array([180, 255, 205])
        lower_red2 = np.array([0, 65, 90])  # red color part 2
        upper_red2 = np.array([13, 255, 205])
        lower_ry3 = np.array([10, 80, 70])  # yellow color
        upper_ry3 = np.array([25, 155, 225])

        # combine the masks
        mask_b = cv2.inRange(hsv, lower_blue, upper_blue)  # BLUE!!
        mask_ry1 = cv2.inRange(hsv, lower_red1, upper_red1)  # RED and YELLOW!
        mask_ry2 = cv2.inRange(hsv, lower_red2, upper_red2)  # RED and YELLOW!
        mask_ry3 = cv2.inRange(hsv, lower_ry3, upper_ry3)  # RED and YELLOW!
        mask_ry4 = cv2.bitwise_or(mask_ry1, mask_ry2)
        mask_ry = cv2.bitwise_or(mask_ry4, mask_ry3)
        mask_total = cv2.bitwise_or(mask_b, mask_ry)

        # Blue color content
        masked_blue = cv2.bitwise_and(image, image, mask=mask_b)
        gray_b = cv2.cvtColor(masked_blue, cv2.COLOR_BGR2GRAY)
        thresh_b = cv2.threshold(gray_b, 0, 255, cv2.THRESH_BINARY)[1]
        result_b = float(cv2.countNonZero(thresh_b)) / area

        # Red color content
        masked_red = cv2.bitwise_and(image, image, mask=mask_ry4)
        gray_r = cv2.cvtColor(masked_red, cv2.COLOR_BGR2GRAY)
        thresh_r = cv2.threshold(gray_r, 0, 255, cv2.THRESH_BINARY)[1]
        result_r = float(cv2.countNonZero(thresh_r)) / area

        # Yellow color content
        masked_yellow = cv2.bitwise_and(image, image, mask=mask_ry3)
        gray_y = cv2.cvtColor(masked_yellow, cv2.COLOR_BGR2GRAY)
        thresh_y = cv2.threshold(gray_y, 0, 255, cv2.THRESH_BINARY)[1]
        result_y = float(cv2.countNonZero(thresh_y)) / area

        colorContent = [result_b, result_r, result_y]

        return colorContent

    def warpImage(self, image, box):
        warp = four_point_transform(image, [box][0])
        # Resize for NN classification
        classificationDim = (64, 64)
        imageWarped = cv2.resize(warp, classificationDim, interpolation=cv2.INTER_LANCZOS4)
        # print("warp")
        return imageWarped

    def publishImage(self, image, name):
        imgPub = rospy.Publisher("/" + name, Image, queue_size=2)

        imgLen = np.array(image).shape
        try:
            if len(imgLen) == 2:
                imgPub.publish(self.bridge.cv2_to_imgmsg(image, "8UC1"))
            else:
                imgPub.publish(self.bridge.cv2_to_imgmsg(image, "bgr8"))
        except CvBridgeError as e:
            print(e)


def main(args):
    # TODO:
    # Add code so that we only look at every 4th image
    rospy.init_node('perception', anonymous=True)
    rate = rospy.Rate(20)

    bridge = CvBridge()
    iw = ImageWorker(bridge)


    # publish the masked image with first contour extraction
    contour_image_pub = rospy.Publisher("/contourimage", Image, queue_size=2)

    print("running...")
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

    clusters = iw.get_clusters()

    with open('cluster_data.csv', 'w') as csvFile:
        writer = csv.writer(csvFile)
        for row in clusters:
            line = str(DICT[int(row[0])])+"\t"+str(row[1])+"\t"+str(row[2])+"\t"+str(row[3])+"\t"+str(0)+"\t"+str(0)+"\t"+str(0)+"\t"+str(0)
            csvFile.write(line)
            csvFile.write('\n')
    csvFile.close()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main(sys.argv)
