# Navigation
## Introduction
In the navigation part, the structure is a loop shape. After taking off, the position of the drone is decided by localization. Then the goal point is set to be in front of the gate. Then A_Star planning is used to plan the path the reach the goal without crushing in to the obstacle. To speed up the process of following the path, a pruning algorithm is used to kill the checkpoint in the middle of a straight line in path. In addition, we want to localize our drone when it is following the routine. We do yaw planning so that the drone can face to the best marker in each checkpoint. Also, since some gate are in certain place so we have to cross a wall, we do height planning, so when two checkpoints are in each side of a wall, we increase the height of drone (0.2m) so that it can cross wall from above. Then we just follow our plan and using localization to make sure we arrive the checkpoint before we move to another. When the drone arrives the end of path, which should be in front of gate, we do “pass gate”. Then the drone will go directly to the checkpoint behind the gate. And come back to the start of loop again, which is path planning.
## Approch taken
### Localication 
This drone has an encoder to update the relative position base on odometry frame, whose origin typically is where the robot was powered on. However, the encoder is not pretty accurate. So we need to calbrate the trasnfrom between map frame and oddmetry frame. In order to get the matrix, <a href="https://docs.opencv.org/3.1.0/d5/dae/tutorial_aruco_detection.html"> Aruco markers</a> were used. The position of the aruco markers in the map is known. Then the position of the markers according to the camera is given by the aruco detection in the base code provided by teaching group. After that, we use transfer function provided by ROS to get detected marker postion base on odometry frame. Then using simple kinematics we can get <a href="https://studywolf.wordpress.com/2013/08/21/robot-control-forward-transformation-matrices/"> transfer matrix</a> from odometry to aruco(<b>To-a</b>) and from map to aruco(<b>Tm-a</b>). Then we can get the transfer matrix from odometry to map (<b>To-m = To-a / Tm-a</b>).   
    
  Because of the quality of camera is not pretty good, the aruco detection can give wrong result. A weight average (low pass filter) and outlier detection are used to make the trasnform more stable.  
#### System test with and without localication
With Localization => [![Watch the video](https://i.ytimg.com/vi/5jr3k8XeNa8/hqdefault.jpg?sqp=-oaymwEZCNACELwBSFXyq4qpAwsIARUAAIhCGAFwAQ==&rs=AOn4CLCKjyK_645n_V81Bb0FyEXOO4Q9lQ)](https://www.youtube.com/watch?v=5jr3k8XeNa8)  
Without Localization => [![Watch the video](https://i.ytimg.com/vi/2B_A5JpAlZ0/hqdefault.jpg?sqp=-oaymwEZCNACELwBSFXyq4qpAwsIARUAAIhCGAFwAQ==&rs=AOn4CLAJWrAVUbBiMTuYWiQqys9CqkriKw)](https://www.youtube.com/watch?v=2B_A5JpAlZ0)

### Path planning
We use 2D A-star planning to avoid obstacles between check points. Since the path provided by A-star is a bunch of points even they are in a straght line and this will decrease the speed of drone, so we do pruning, in which we delete the points between the start point and end point of a straght line. Also, in some of the situation 2D planning will give a pretty long path but pretty simple to go with 3D planning. But 3D planning will cost more computation. So, we do some height planning. First, do 2D planning and pruning in the map without obstacle. Then check if there are any obastacle between the check points. Add two check points in both side of obstacle and give them a higher height. In addition, in order to get more accurate drone position, the camera should look at the markers as much as possible. So we do yaw planning. Find the closest marker and add the corresponding yaw angle to the check points.   

### Demo of path planning

